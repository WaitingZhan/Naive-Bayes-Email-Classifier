{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import string\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##This will produce two lists: the data list, where each element is the text of an email, and the target list, which is simply binary (1 mean- ing spam and 0 meaning ham). Now letâ€™s create a class and add some helper functions for string manipulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-5-82932207fc87>, line 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-82932207fc87>\"\u001b[0;36m, line \u001b[0;32m11\u001b[0m\n\u001b[0;31m    with open(os.path.join(DATA_DIR, subfolder, 'spam', spam_file), enco data.append(f.read())\u001b[0m\n\u001b[0m                                                                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = 'enron'\n",
    "target_names = ['ham', 'spam']\n",
    "def get_data(DATA_DIR):\n",
    "    subfolders = ['enron%d' % i for i in range(1,7)]\n",
    "    data = []\n",
    "    target = []\n",
    "    for subfolder in subfolders:\n",
    "    # spam\n",
    "        spam_files = os.listdir(os.path.join(DATA_DIR, subfolder, 'spam'))\n",
    "    for spam_file in spam_files:\n",
    "        with open(os.path.join(DATA_DIR, subfolder, 'spam', spam_file), enco data.append(f.read())\n",
    "        target.append(1)\n",
    "    # ham\n",
    "    ham_files = os.listdir(os.path.join(DATA_DIR, subfolder, 'ham')) \n",
    "    for ham_file in ham_files:\n",
    "        with open(os.path.join(DATA_DIR, subfolder, 'ham', ham_file), encodi data.append(f.read())\n",
    "        target.append(0)\n",
    "    return data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##We have a function to clean up our string by removing punctuation, one to tokenize our string into words, and another to count up how many of each word appears in a list of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpamDetector(object):\n",
    "\"\"\"Implementation of Naive Bayes for binary classification\"\"\" def clean(self, s):\n",
    "translator = str.maketrans(\"\", \"\", string.punctuation) return s.translate(translator)\n",
    "def tokenize(self, text):\n",
    "text = self.clean(text).lower() return re.split(\"\\W+\", text)\n",
    "def get_word_counts(self, words): word_counts = {}\n",
    "for word in words:\n",
    "word_counts[word] = word_counts.get(word, 0.0) + 1.0\n",
    "return word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(self, X, Y): \n",
    "    self.num_messages = {} \n",
    "    self.log_class_priors = {} \n",
    "    self.word_counts = {} \n",
    "    self.vocab = set()\n",
    "    n = len(X)\n",
    "    self.num_messages['spam'] = sum(1 for label in Y if label == 1) \n",
    "    self.num_messages['ham'] = sum(1 for label in Y if label == 0) \n",
    "    self.log_class_priors['spam'] = math.log(self.num_messages['spam'] / n) \n",
    "    self.log_class_priors['ham'] = math.log(self.num_messages['ham'] / n)\n",
    "    self.word_counts['spam'] = {} self.word_counts['ham'] = {}\n",
    "    for x, y in zip(X, Y):\n",
    "        c = 'spam' if y == 1 else 'ham'\n",
    "        counts = self.get_word_counts(self.tokenize(x)) for word, count in counts.items():\n",
    "        if word not in self.vocab: \n",
    "            self.vocab.add(word)\n",
    "        if word not in self.word_counts[c]: \n",
    "            self.word_counts[c][word] = 0.0\n",
    "        self.word_counts[c][word] += count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(self, X): result = []\n",
    "    for x in X:\n",
    "        counts = self.get_word_counts(self.tokenize(x)) spam_score = 0\n",
    "        ham_score = 0\n",
    "    for word, _ in counts.items():\n",
    "        if word not in self.vocab: continue\n",
    "            # add Laplace smoothing\n",
    "            log_w_given_spam = math.log( (self.word_counts['spam'].get(word, 0.0) \n",
    "            log_w_given_ham = math.log( (self.word_counts['ham'].get(word, 0.0)\n",
    "        \n",
    "            spam_score += log_w_given_spam\n",
    "            ham_score += log_w_given_ham\n",
    "            spam_score += self.log_class_priors['spam'] \n",
    "            ham_score += self.log_class_priors['ham']\n",
    "        if spam_score > ham_score: \n",
    "            result.append(1)\n",
    "        else: \n",
    "            result.append(0)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    X, y = get_data(DATA_DIR) \n",
    "    MNB = SpamDetector() \n",
    "    MNB.fit(X[100:], y[100:])\n",
    "    pred = MNB.predict(X[:100]) \n",
    "    true = y[:100]\n",
    "    accuracy = sum(1 for i in range(len(pred)) if pred[i] == true[i]) / float(len(pred)) \n",
    "    print(\"{0:.4f}\".format(accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
